{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip uninstall -y transformer_lens\n",
    "! pip install git+https://github.com/taufeeque9/TransformerLens/\n",
    "! pip install git+https://github.com/minyoungg/vqtorch/\n",
    "! pip install termcolor\n",
    "! pip install -U accelerate\n",
    "! pip install -U kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(tensor, renderer=None, **kwargs):\n",
    "    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", **kwargs).show(renderer)\n",
    "\n",
    "def line(tensor, renderer=None, **kwargs):\n",
    "    px.line(y=utils.to_numpy(tensor), **kwargs).show(renderer)\n",
    "\n",
    "def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n",
    "    x = utils.to_numpy(x)\n",
    "    y = utils.to_numpy(y)\n",
    "    px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/codebook-features/codebook_features/train_toy_model.py:393: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"config\", config_name=\"toy_main\")\n"
     ]
    }
   ],
   "source": [
    "from termcolor import colored\n",
    "import plotly.express as px\n",
    "import transformers\n",
    "import codebook_features\n",
    "import torch\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import copy\n",
    "import wandb\n",
    "import json\n",
    "import transformer_lens.utils as utils\n",
    "from collections import namedtuple\n",
    "from functools import partial\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from transformers import GPTNeoXConfig, GPTNeoXForCausalLM, GPT2TokenizerFast, pipeline, set_seed\n",
    "from torch.utils.data import IterableDataset\n",
    "from codebook_features import models, run_clm, train_toy_model, trainer as cb_trainer\n",
    "from codebook_features.utils import *\n",
    "from codebook_features.toy_utils import *\n",
    "import os\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "def logits_to_pred(logits, k=5):\n",
    "    sorted_logits, sorted_indices = torch.sort(logits, descending=True, dim=-1)\n",
    "    probs = sorted_logits.softmax(dim=-1)\n",
    "    topk_preds = [tokenizer.convert_ids_to_tokens(e) for e in sorted_indices[:, -1, :k]]\n",
    "    topk_preds = [tokenizer.convert_tokens_to_string([e]) for batch in topk_preds for e in batch]\n",
    "    return [(topk_preds[i], probs[:, -1, i].item()) for i in range(len(topk_preds))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hp = dict(\n",
    "    run_name = \"cb_model_neox\",\n",
    "    tags = [],\n",
    "    num_states = 100,\n",
    "    num_edges = 10,\n",
    "    seq_len = 128,\n",
    "    vocab_size = 11,\n",
    "#     hidden_size = 64,\n",
    "#     intermediate_size = 256,\n",
    "    hidden_size = 128,\n",
    "    intermediate_size = 512,\n",
    "    num_hidden_layers = 4,\n",
    "    num_attention_heads = 4,\n",
    "    rotary_emb_base = 10000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for 4circle\n",
    "hp = dict(\n",
    "    run_name = \"cb_model_neox\",\n",
    "    tags = [],\n",
    "    num_states = 4,\n",
    "    num_edges = 1,\n",
    "    seq_len = 128,\n",
    "    vocab_size = 3,\n",
    "#     hidden_size = 64,\n",
    "#     intermediate_size = 256,\n",
    "    hidden_size = 16,\n",
    "    intermediate_size = 64,\n",
    "    num_hidden_layers = 1,\n",
    "    num_attention_heads = 1,\n",
    "    rotary_emb_base = 10000,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained on 4circle\n",
    "base_path = \"/data/outputs/2023-06-02/03-05-17/\"\n",
    "checkpoint = \"checkpoint-6500/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained on 100s\n",
    "base_path = \"/data/outputs/2023-06-02/03-38-51/\"\n",
    "checkpoint = \"checkpoint-9500/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft only attn 100s\n",
    "base_path = \"/data/outputs/2023-06-07/21-33-13/\"\n",
    "checkpoint = \"checkpoint-18000/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft on multi k 100s\n",
    "base_path = \"/data/outputs/2023-06-08/12-50-15/\"\n",
    "checkpoint = \"checkpoint-13000/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft-cb on 4circle\n",
    "base_path = \"/data/outputs/2023-05-30/11-59-03/\"\n",
    "checkpoint = \"checkpoint-500/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained on 100 states\n",
    "base_path = \"/data/codebook-features/codebook_features/outputs/2023-05-25/12-56-03/\"\n",
    "checkpoint = \"checkpoint-4500/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft on 100 states\n",
    "base_path = \"/data/outputs/2023-06-02/06-12-08/\"\n",
    "checkpoint = \"checkpoint-15500/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/data/codebook-features/codebook_features/outputs/2023-05-20/13-27-44/\"\n",
    "checkpoint = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft-cb on 100 states\n",
    "base_path = \"/data/codebook-features/codebook_features/outputs/2023-05-26/11-01-04/\"\n",
    "checkpoint = \"checkpoint-17500/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab:\n",
      "{\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\": 4, \"5\": 5, \"6\": 6, \"7\": 7, \"8\": 8, \"9\": 9, \"<|endoftext|>\": 10}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = train_toy_model.create_tokenizer(base_path+\"toy\", hp[\"vocab_size\"])\n",
    "# automata = train_toy_model.ToyGraph(N=hp[\"num_states\"], edges=hp[\"num_edges\"], seed=42)\n",
    "automata = train_toy_model.ToyGraph.load(base_path + \"toy/automata.npy\",representation_base=hp[\"vocab_size\"]-1, seed=42)\n",
    "train_dataset = train_toy_model.ToyDataset(automata, tokenizer=tokenizer, seq_len=hp[\"seq_len\"])\n",
    "eval_dataset = train_toy_model.ToyDataset(automata, tokenizer=tokenizer, seq_len=hp[\"seq_len\"], max_samples=2048)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base model\n",
    "device = \"cuda\"\n",
    "from transformers import AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained(base_path + \"output_toy/\" + checkpoint)\n",
    "model = model.to(device).eval()\n",
    "config = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_seq = tokenizer.decode(model.generate(max_length=hp[\"seq_len\"], do_sample=True)[0])\n",
    "traj = automata.seq_to_traj(gen_seq)\n",
    "acc, _ = automata.transition_accuracy(traj)\n",
    "print(gen_seq)\n",
    "print(traj)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 7.152557373046875e-06 5.364418029785156e-05 2.315725088119507\n"
     ]
    }
   ],
   "source": [
    "# cb model\n",
    "device = \"cpu\"\n",
    "config = GPTNeoXConfig(vocab_size=hp[\"vocab_size\"], hidden_size=hp[\"hidden_size\"], num_hidden_layers=hp[\"num_hidden_layers\"], num_attention_heads=hp[\"num_attention_heads\"], intermediate_size=hp[\"intermediate_size\"], rotary_emb_base=hp[\"rotary_emb_base\"], bos_token_id=hp[\"vocab_size\"]-1, eos_token_id=hp[\"vocab_size\"]-1, max_position_embeddings=hp[\"seq_len\"])\n",
    "config.architectures = [\"GPTNeoXForCausalLM\"]\n",
    "model = GPTNeoXForCausalLM(config=config)\n",
    "model = model.to(device).eval()\n",
    "orig_cb_model = models.wrap_codebook(model_or_path=model, pretrained_path=base_path+f\"output_toy/{checkpoint}\")\n",
    "orig_cb_model = orig_cb_model.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 5.7220458984375e-06 2.7179718017578125e-05 1.4187428951263428\n"
     ]
    }
   ],
   "source": [
    "# hooked model\n",
    "hooked_kwargs = dict(center_unembed=False,center_writing_weights=False,fold_ln=False,fold_value_biases=False,refactor_factored_attn_matrices=False,device=device)\n",
    "cb_model = models.convert_to_hooked_model_for_toy(base_path+f\"output_toy/{checkpoint}\", orig_cb_model, config=config, hooked_kwargs=hooked_kwargs)\n",
    "cb_model = cb_model.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_to = \"none\"\n",
    "# report_to = \"all\"\n",
    "training_args = run_clm.TrainingArguments(\n",
    "#     no_cuda=True,\n",
    "    output_dir=\"toy/output\",\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_train_batch_size=512,\n",
    "    per_device_eval_batch_size=512,\n",
    "    learning_rate=1e-3,\n",
    "#     weight_decay=1e-1,\n",
    "    max_steps=20000,\n",
    "#     lr_scheduler_type=\"linear\",\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    warmup_ratio=0.1,\n",
    "    logging_first_step=True,\n",
    "    logging_steps=500,\n",
    "    eval_steps=500,\n",
    "    overwrite_output_dir=True,\n",
    "    seed=42,\n",
    "    train_model_params=True,\n",
    "    model_lr_factor=1.0,\n",
    "    report_to=report_to,\n",
    "    dataloader_num_workers=8,\n",
    "\n",
    ")\n",
    "\n",
    "cfg_dict = {\"training_args\": training_args.__dict__, \"model_args\": config.__dict__ if config else None}\n",
    "cfg_dict = {**hp, **cfg_dict}\n",
    "model_args = run_clm.ModelArguments(model_name_or_path=\"toy/model\")\n",
    "data_args = run_clm.DataTrainingArguments(dataset_name=\"toy_graph\", max_eval_samples=2048)\n",
    "\n",
    "optimizers = (None, None)\n",
    "if isinstance(model, models.CodebookModel):\n",
    "    if training_args.train_model_params:\n",
    "        params = [\n",
    "            {\n",
    "                \"params\": model.get_codebook_params(),\n",
    "                \"lr\": training_args.learning_rate,\n",
    "                # weight decay for codebook params is used through\n",
    "                # `codebook_weight_decay` param that is used directly\n",
    "                # to compute regularized loss.\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "            {\n",
    "                \"params\": model.get_model_params(),\n",
    "                \"lr\": training_args.model_lr_factor * training_args.learning_rate,\n",
    "                \"weight_decay\": training_args.weight_decay,\n",
    "            },\n",
    "        ]\n",
    "    else:\n",
    "        params = model.get_codebook_params()\n",
    "    if len(params) > 0:\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            params,\n",
    "            training_args.learning_rate,\n",
    "        )\n",
    "        optimizers = (optimizer, None)\n",
    "\n",
    "callbacks = []\n",
    "# if report_to == \"all\":\n",
    "#     callbacks = [cb_trainer.WandbCallback()]\n",
    "\n",
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    if isinstance(logits, tuple):\n",
    "        # Depending on the model and config, logits may contain extra tensors,\n",
    "        # like past_key_values, but logits always come first\n",
    "        logits = logits[0]\n",
    "    return logits.argmax(dim=-1)\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    # preds have the same shape as the labels, after the argmax(-1) has been calculated\n",
    "    # by preprocess_logits_for_metrics but we need to shift the labels\n",
    "    labels = labels[:, 1:].reshape(-1)\n",
    "    preds = preds[:, :-1].reshape(-1)\n",
    "    return metric.compute(predictions=preds, references=labels)\n",
    "\n",
    "trainer = train_toy_model.ToyModelTrainer(\n",
    "    model=model,\n",
    "    toy_graph=automata,\n",
    "    gen_seq_len=hp[\"seq_len\"],\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    "    optimizers=optimizers,\n",
    "    callbacks=callbacks,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "\n",
    "generator = pipeline('text-generation', model=model, tokenizer=tokenizer, device=0)\n",
    "gen_seq = generator(\"\", max_length=50, do_sample=True, temperature=0.7)[0]['generated_text']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = orig_cb_model\n",
    "# model = cb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_answer = \"49\"\n",
    "# example_prompt = f\"33\" # 3 4 6 1 2\n",
    "# example_prompt = f\"63\" # 9 8 5 7 4 6\n",
    "# example_prompt = f\"47\" # 0 1 2 3 4 5 8\n",
    "# example_prompt = f\"71\" # 1 3 4 5 8 0 2\n",
    "# example_prompt = f\"72\" # 8 9 4 5 7 3\n",
    "example_prompt = f\"34\" # 4 5 7 1 6 8\n",
    "utils.test_prompt(example_prompt, example_answer, cb_model, prepend_bos=True, prepend_space_to_answer=False, top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    print(automata.nbrs(i), \"-\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_model.reset_hook_kwargs()\n",
    "base_state = 636\n",
    "base_input = cb_model.to_tokens(automata.traj_to_str([base_state]), prepend_bos=True)\n",
    "base_input = base_input.to(device)\n",
    "base_logits, base_cache = cb_model.run_with_cache(base_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_state = 336\n",
    "corrupted_input = cb_model.to_tokens(automata.traj_to_str([corrupted_state]), prepend_bos=True)\n",
    "corrupted_input = corrupted_input.to(device)\n",
    "corrupted_logits, corrupted_cache = cb_model.run_with_cache(corrupted_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = True\n",
    "# answer_tokens_both = torch.tensor([[1, 0]], device=cb_model.cfg.device)\n",
    "answer_tokens_both = torch.tensor([[3, 9]], device=cb_model.cfg.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9996, device='cuda:0') tensor(-0.5823, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def logits_to_ave_logit_diff(logits, answer_tokens, per_prompt=False):\n",
    "    # Only the final logits are relevant for the answer\n",
    "    final_logits = logits[:, -1, :]\n",
    "    answer_logits = final_logits.gather(dim=-1, index=answer_tokens)\n",
    "    answer_logit_diff = answer_logits[:, 0] - answer_logits[:, 1]\n",
    "    if per_prompt:\n",
    "        return answer_logit_diff\n",
    "    else:\n",
    "        return answer_logit_diff.mean()\n",
    "\n",
    "def normalize_patched_logit_diff(patched_logit_diff):\n",
    "    # Subtract corrupted logit diff to measure the improvement, divide by the total improvement from clean to corrupted to normalise\n",
    "    # 0 means zero change, negative means actively made worse, 1 means totally recovered clean performance, >1 means actively *improved* on clean performance\n",
    "    return (patched_logit_diff - corrupted_average_logit_diff)/(base_average_logit_diff - corrupted_average_logit_diff)\n",
    "\n",
    "\n",
    "\n",
    "base_average_logit_diff = logits_to_ave_logit_diff(base_logits.softmax(dim=-1) if softmax else base_logits, answer_tokens_both)\n",
    "corrupted_average_logit_diff = logits_to_ave_logit_diff(corrupted_logits.softmax(dim=-1) if softmax else corrupted_logits, answer_tokens_both)\n",
    "\n",
    "print(base_average_logit_diff, corrupted_average_logit_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.390800803899765, 0.0, 0.0, 0.7187427282333374, 0.0, 0.1705697625875473, 0.1652897596359253, 0.017624331638216972, 0.22878846526145935, 0.9348824620246887, 0.07006233185529709, 0.18100808560848236, 0.20456857979297638, 0.24130479991436005, 0.2563377916812897, 0.016519445925951004, -0.007724066264927387, -0.07203540951013565, -0.009037615731358528, 0.2594574987888336]\n",
      "[tensor(0.0359, device='cuda:0'), tensor(-0.5823, device='cuda:0'), tensor(-0.5823, device='cuda:0'), tensor(0.5547, device='cuda:0'), tensor(-0.5823, device='cuda:0'), tensor(-0.3125, device='cuda:0'), tensor(-0.3208, device='cuda:0'), tensor(-0.5544, device='cuda:0'), tensor(-0.2204, device='cuda:0'), tensor(0.8966, device='cuda:0'), tensor(-0.4715, device='cuda:0'), tensor(-0.2960, device='cuda:0'), tensor(-0.2587, device='cuda:0'), tensor(-0.2006, device='cuda:0'), tensor(-0.1768, device='cuda:0'), tensor(-0.5562, device='cuda:0'), tensor(-0.5945, device='cuda:0'), tensor(-0.6962, device='cuda:0'), tensor(-0.5966, device='cuda:0'), tensor(-0.1718, device='cuda:0')]\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Layer=%{x}<br>Normalized Logit Difference=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          "L0H0",
          "L0H1",
          "L0H2",
          "L0H3",
          "L0MLP",
          "L1H0",
          "L1H1",
          "L1H2",
          "L1H3",
          "L1MLP",
          "L2H0",
          "L2H1",
          "L2H2",
          "L2H3",
          "L2MLP",
          "L3H0",
          "L3H1",
          "L3H2",
          "L3H3",
          "L3MLP"
         ],
         "xaxis": "x",
         "y": [
          0.390800803899765,
          0,
          0,
          0.7187427282333374,
          0,
          0.1705697625875473,
          0.1652897596359253,
          0.017624331638216972,
          0.22878846526145935,
          0.9348824620246887,
          0.07006233185529709,
          0.18100808560848236,
          0.20456857979297638,
          0.24130479991436005,
          0.2563377916812897,
          0.016519445925951004,
          -0.007724066264927387,
          -0.07203540951013565,
          -0.009037615731358528,
          0.2594574987888336
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Logit Difference for Nth layers' codes for pos [-1]"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Layer"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Normalized Logit Difference"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"0f9ee08d-a2d3-42bb-93cf-b0d4020c4b6d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0f9ee08d-a2d3-42bb-93cf-b0d4020c4b6d\")) {                    Plotly.newPlot(                        \"0f9ee08d-a2d3-42bb-93cf-b0d4020c4b6d\",                        [{\"hovertemplate\":\"Layer=%{x}<br>Normalized Logit Difference=%{y}<extra></extra>\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[\"L0H0\",\"L0H1\",\"L0H2\",\"L0H3\",\"L0MLP\",\"L1H0\",\"L1H1\",\"L1H2\",\"L1H3\",\"L1MLP\",\"L2H0\",\"L2H1\",\"L2H2\",\"L2H3\",\"L2MLP\",\"L3H0\",\"L3H1\",\"L3H2\",\"L3H3\",\"L3MLP\"],\"xaxis\":\"x\",\"y\":[0.390800803899765,0.0,0.0,0.7187427282333374,0.0,0.1705697625875473,0.1652897596359253,0.017624331638216972,0.22878846526145935,0.9348824620246887,0.07006233185529709,0.18100808560848236,0.20456857979297638,0.24130479991436005,0.2563377916812897,0.016519445925951004,-0.007724066264927387,-0.07203540951013565,-0.009037615731358528,0.2594574987888336],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Layer\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Normalized Logit Difference\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Logit Difference for Nth layers' codes for pos [-1]\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('0f9ee08d-a2d3-42bb-93cf-b0d4020c4b6d');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from functools import partial\n",
    "scores, logit_diffs = [], []\n",
    "pos = [-1]\n",
    "# pos = list(range(17))\n",
    "for i in range(cb_model.cfg.n_layers):\n",
    "    for head in list(range(cb_model.cfg.n_heads)) + [None]:\n",
    "        hook_fn = partial(patch_codebook_ids, pos=pos, cache=base_cache)#, code_idx=list(range(32)))\n",
    "        cb_model.reset_codebook_metrics()\n",
    "        if head is not None:\n",
    "            cb_str = f'blocks.{i}.attn.codebook_layer.codebook.{head}.hook_codebook_ids'\n",
    "        else:\n",
    "            cb_str = f'blocks.{i}.mlp.codebook_layer.hook_codebook_ids'\n",
    "        patched_logits = cb_model.run_with_hooks(\n",
    "            corrupted_input,\n",
    "            fwd_hooks = [(cb_str, hook_fn)],\n",
    "            return_type=\"logits\"\n",
    "        )\n",
    "        patched_logit_diff = logits_to_ave_logit_diff(patched_logits.softmax(dim=-1) if softmax else patched_logits, answer_tokens_both)\n",
    "        logit_diffs.append(patched_logit_diff)\n",
    "    #     print(patched_logit_diff)\n",
    "        scores.append(normalize_patched_logit_diff(patched_logit_diff).item())\n",
    "        if patched_logit_diff < -6:\n",
    "            print(\"pred:\", i, head)\n",
    "            print(logits_to_pred(patched_logits,k=5))\n",
    "    #     scores.append(patched_logit_diff.item())\n",
    "\n",
    "# scores.append(normalize_patched_logit_diff(corrupted_average_logit_diff).item())\n",
    "print(scores)\n",
    "print(logit_diffs)\n",
    "x_label = [f\"L{l}H{h}\" if h is not None else f\"L{l}MLP\" for l in range(cb_model.cfg.n_layers) for h in list(range(cb_model.cfg.n_heads)) + [None]]\n",
    "line(scores, x=x_label, title=f\"Logit Difference for Nth layers' codes for pos {pos}\", labels={\"y\":\"Normalized Logit Difference\", \"x\": \"Layer\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Code Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_samples = 10*1024\n",
    "model = orig_cb_model\n",
    "model.enable_logging()\n",
    "model.reset_codebook_metrics()\n",
    "train_dataset_tkns = train_toy_model.ToyDataset(automata, tokenizer=tokenizer, seq_len=128, max_samples=max_samples, save_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:10 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.204332709312439, 'eval_accuracy': 0.46034617987204723, 'eval_runtime': 32.5704, 'eval_samples_per_second': 314.396, 'eval_steps_per_second': 0.614, 'eval_transition_accuracy': 0.7519354838709678, 'eval_first_transition_accuracy': 0.98, 'eval_multicode_k': 1, 'eval_dead_code_fraction/layer0': 0.9267, 'eval_MSE/layer0': 29718.738983438758, 'eval_input_norm/layer0': 127.66250211015993, 'eval_output_norm/layer0': 10.971974760256575, 'eval_dead_code_fraction/layer1': 0.382, 'eval_MSE/layer1': 68.49746054299729, 'eval_input_norm/layer1': 6.285440554106894, 'eval_output_norm/layer1': 11.180642855833774, 'eval_dead_code_fraction/layer2': 0.1394, 'eval_MSE/layer2': 151.147979416076, 'eval_input_norm/layer2': 6.778055443413886, 'eval_output_norm/layer2': 14.170335556351365, 'eval_dead_code_fraction/layer3': 0.4526, 'eval_MSE/layer3': 184.61280731194486, 'eval_input_norm/layer3': 8.196509695231274, 'eval_output_norm/layer3': 15.474042212992469}\n",
      "dict_keys(['layer0_attn_preproj_ccb0', 'layer0_attn_preproj_ccb1', 'layer0_attn_preproj_ccb2', 'layer0_attn_preproj_ccb3', 'layer0_mlp', 'layer1_attn_preproj_ccb0', 'layer1_attn_preproj_ccb1', 'layer1_attn_preproj_ccb2', 'layer1_attn_preproj_ccb3', 'layer1_mlp', 'layer2_attn_preproj_ccb0', 'layer2_attn_preproj_ccb1', 'layer2_attn_preproj_ccb2', 'layer2_attn_preproj_ccb3', 'layer2_mlp', 'layer3_attn_preproj_ccb0', 'layer3_attn_preproj_ccb1', 'layer3_attn_preproj_ccb2', 'layer3_attn_preproj_ccb3', 'layer3_mlp'])\n",
      "(10240, 128)\n",
      "(10240, 128, 4)\n",
      "(10240, 128, 4)\n"
     ]
    }
   ],
   "source": [
    "trainer.args.dataloader_num_workers = 0\n",
    "trainer.args.report_on = \"none\"\n",
    "trainer.model = model\n",
    "codebook_acts = {}\n",
    "def store_cb_activations(key, codebook_ids, codebook_acts=codebook_acts):\n",
    "    assert len(codebook_ids.shape) == 3  # (bs, seq_len, k_codebook)\n",
    "    if key not in codebook_acts:\n",
    "        codebook_acts[key] = []\n",
    "    codebook_acts[key].append(codebook_ids)\n",
    "\n",
    "model.set_hook_fn(store_cb_activations)\n",
    "trainer.model = model\n",
    "\n",
    "metrics = trainer.evaluate(eval_dataset=train_dataset_tkns)\n",
    "print(metrics)\n",
    "\n",
    "# len(train_dataset_tkns.tokens)\n",
    "print(codebook_acts.keys())\n",
    "cb_acts = codebook_acts\n",
    "num_codes = 10000\n",
    "from tqdm import tqdm\n",
    "for k, v in codebook_acts.items():\n",
    "    v_len_to_get = max_samples//v[0].shape[0]\n",
    "    cb_acts[k] = np.concatenate(v[:v_len_to_get], axis=0)\n",
    "\n",
    "tokens = np.vstack(train_dataset_tkns.tokens)\n",
    "print(tokens.shape)\n",
    "print(cb_acts['layer1_attn_preproj_ccb0'].shape)\n",
    "print(cb_acts['layer2_mlp'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_automata = automata.reverse()\n",
    "\n",
    "is_trigram = False\n",
    "prefix_random_states_len = 10\n",
    "plot_code_grp_distr = False\n",
    "\n",
    "repeat = 3 if is_trigram else 2\n",
    "\n",
    "js_divs = {}\n",
    "all_state_info = {}\n",
    "\n",
    "chars = [str(i) for i in range(automata.representation_base)]\n",
    "all_valid_inputs = [''.join(combination) for combination in itertools.product(chars, repeat=repeat) if valid_input(''.join(combination), automata)]\n",
    "all_valid_inputs_tokens = tokenizer(all_valid_inputs, return_tensors=\"pt\")[\"input_ids\"].to(\n",
    "    cb_model.cfg.device\n",
    ")\n",
    "if prefix_random_states_len > 0:\n",
    "    start_states = [s[0] for s in automata.seq_to_traj(all_valid_inputs)]\n",
    "    random_state_prefix = rev_automata.generate_trajectories(prefix_random_states_len, start_states=start_states)\n",
    "    random_state_prefix = random_state_prefix[:, ::-1]\n",
    "    random_state_prefix = random_state_prefix.astype(int)\n",
    "    random_state_prefix = [automata.traj_to_str(traj) for traj in random_state_prefix]\n",
    "    random_state_prefix = tokenizer(random_state_prefix, return_tensors=\"pt\")[\"input_ids\"].to(\n",
    "        cb_model.cfg.device\n",
    "    )\n",
    "    all_valid_inputs_tokens = torch.cat([random_state_prefix, all_valid_inputs_tokens], dim=1)\n",
    "all_valid_inputs_tokens = F.pad(all_valid_inputs_tokens, (1, 0), value=tokenizer.bos_token_id)\n",
    "\n",
    "for input in tqdm(all_valid_inputs):\n",
    "    input_tensor = cb_model.to_tokens(str(input), prepend_bos=True).to(device)\n",
    "    logits, cache = cb_model.run_with_cache(input_tensor)\n",
    "    all_state_info[input] = (logits, cache)\n",
    "\n",
    "for iter_a, input_a in enumerate(all_valid_inputs):\n",
    "    for input_b in all_valid_inputs[iter_a+1:]:\n",
    "        js_divs[(input_a, input_b)] = JSD(all_state_info[input_a][0], all_state_info[input_b][0]).item()\n",
    "\n",
    "avg_js_div = sum(js_divs.values()) / len(js_divs)\n",
    "\n",
    "if plot_code_grp_distr:\n",
    "    code_groups_for_all_comps = {}\n",
    "    for layer in tqdm(range(cb_model.cfg.n_layers)):\n",
    "        for ccb_num in range(cb_model.cfg.n_heads):\n",
    "            code_groups_for_all_comps[(layer, \"attn\", ccb_num)] = partition_input_on_codebook(cb_model=cb_model, automata=automata, layer=layer, cb_at=\"attn\", ccb_num=ccb_num, input_len=3)\n",
    "        code_groups_for_all_comps[(layer, \"mlp\", None)] = partition_input_on_codebook(cb_model=cb_model, automata=automata, layer=layer, cb_at=\"mlp\", ccb_num=None, input_len=3)\n",
    "\n",
    "all_states_tokens = all_valid_inputs_tokens\n",
    "all_states_logits = torch.cat([v[0] for v in all_state_info.values()], dim=0)\n",
    "all_states_cache = {k: v[1] for k, v in all_state_info.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "686it [1:34:37,  8.28s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "type": "bar",
         "x": [
          "None",
          "L0 Attn",
          "L1 MLP",
          "All Attn",
          "All MLP",
          "All Attn, MLP"
         ],
         "y": [
          1,
          0.7969451836499092,
          0.8585448990769184,
          0.3258626118779689,
          0.11651101004735498,
          0.00010922327548067296
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "k=4 Model: JS Div on Code Patching for Trigrams"
        },
        "xaxis": {
         "title": {
          "text": "Code Patching Components"
         }
        },
        "yaxis": {
         "title": {
          "text": "Normalized JS Div"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"785a1dd7-8172-47c0-a138-a181f48949ed\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"785a1dd7-8172-47c0-a138-a181f48949ed\")) {                    Plotly.newPlot(                        \"785a1dd7-8172-47c0-a138-a181f48949ed\",                        [{\"x\":[\"None\",\"L0 Attn\",\"L1 MLP\",\"All Attn\",\"All MLP\",\"All Attn, MLP\"],\"y\":[1.0,0.7969451836499092,0.8585448990769184,0.3258626118779689,0.11651101004735498,0.00010922327548067296],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"k=4 Model: JS Div on Code Patching for Trigrams\"},\"xaxis\":{\"title\":{\"text\":\"Code Patching Components\"}},\"yaxis\":{\"title\":{\"text\":\"Normalized JS Div\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('785a1dd7-8172-47c0-a138-a181f48949ed');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "patchings_to_plot_orig = [\"none\", \"l0_attn\", \"l1_mlp\", \"all_attn\", \"all_mlp\", \"all_attn_mlp\"]\n",
    "patchings_to_plot = [s.replace(\"all\", \"l0,l1,l2,l3\") for s in patchings_to_plot_orig]\n",
    "\n",
    "js_divs = {k: 0 for k in patchings_to_plot}\n",
    "js_divs[\"none\"] = 0\n",
    "\n",
    "input_list = all_valid_inputs\n",
    "for state_b, input_b in tqdm(enumerate(input_list)):\n",
    "    js_divs_w_b = JSD(all_states_logits, all_states_logits[state_b].unsqueeze(0), reduction=\"none\").sum() / (automata.N - 1) # removing b as JSD(b,b) = 0\n",
    "    js_divs[\"none\"] += js_divs_w_b\n",
    "\n",
    "    for patching in patchings_to_plot:\n",
    "        if patching == \"none\":\n",
    "            continue\n",
    "        cb_at = patching.split(\"_\")[1:]\n",
    "        layers = get_layers_from_patching_str(patching)\n",
    "        heads = [None] * len(cb_at)\n",
    "        if \"attn\" in cb_at:\n",
    "            attn_idx = cb_at.index(\"attn\")\n",
    "            cb_at.pop(attn_idx), heads.pop(attn_idx)\n",
    "            cb_at += [\"attn\"] * cb_model.cfg.n_heads\n",
    "            heads += list(range(cb_model.cfg.n_heads))\n",
    "        cb_at_rep = cb_at * len(layers)\n",
    "        heads_rep = heads * len(layers)\n",
    "        layers_rep = []\n",
    "        for l in layers:\n",
    "            layers_rep += [l] * len(cb_at)\n",
    "        \n",
    "        cache_b = all_state_info[input_b][1]\n",
    "        code = [cache_b[get_cb_layer_name(cb_at_rep[i], layers_rep[i], heads_rep[i])][0, -1, :] for i in range(len(cb_at_rep))]\n",
    "\n",
    "        mod_logits, mod_cache = run_with_codes(\n",
    "            all_states_tokens,\n",
    "            cb_model,\n",
    "            code,\n",
    "            cb_at_rep,\n",
    "            layers_rep,\n",
    "            heads_rep,\n",
    "            pos=[-1],\n",
    "        )\n",
    "        js_divs_w_b = JSD(mod_logits, all_states_logits[state_b].unsqueeze(0), reduction=\"none\").sum() / (automata.N - 1) # removing b as JSD(b,b) = 0\n",
    "        js_divs[patching] += js_divs_w_b\n",
    "\n",
    "js_divs = [js_divs[k].item() / automata.N for k in patchings_to_plot]\n",
    "js_divs = [js_div / max(js_divs) for js_div in js_divs]\n",
    "\n",
    "# plot js_divs using plotly\n",
    "fig = go.Figure()\n",
    "x_labels = [clean_patching_name(patching) for patching in patchings_to_plot_orig]\n",
    "fig.add_trace(go.Bar(x=x_labels, y=js_divs))\n",
    "fig.update_layout(title=f'k=4 Model: JS Div on Code Patching for {\"Trigrams\" if is_trigram else \"Bigrams\"}', xaxis_title='Code Patching Components', yaxis_title='Normalized JS Div')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat = 2\n",
    "\n",
    "chars = [str(i) for i in range(automata.representation_base)]\n",
    "all_valid_inputs = [''.join(combination) for combination in itertools.product(chars, repeat=repeat) if valid_input(''.join(combination), automata)]\n",
    "\n",
    "js_divs = {}\n",
    "state_logits = {}\n",
    "for state_a in all_valid_inputs:\n",
    "    a_input = cb_model.to_tokens(state_a, prepend_bos=True).to(device)\n",
    "    a_logits = cb_model(a_input)\n",
    "    state_logits[state_a] = a_logits\n",
    "\n",
    "for iter_a, state_a in enumerate(all_valid_inputs):\n",
    "    for state_b in all_valid_inputs[iter_a+1:]:\n",
    "        # kl_divs[(state_a, state_b)] = F.kl_div(F.log_softmax(state_logits[state_a], dim=-1), F.log_softmax(state_logits[state_b], dim=-1), log_target=True, reduction=\"batchmean\").item()\n",
    "        js_divs[(state_a, state_b)] = JSD(state_logits[state_a], state_logits[state_b]).item()\n",
    "\n",
    "avg_js_div = sum(js_divs.values()) / len(js_divs)\n",
    "\n",
    "code_groups_for_all_comps = {}\n",
    "for layer in tqdm(range(cb_model.cfg.n_layers)):\n",
    "    for ccb_num in range(cb_model.cfg.n_heads):\n",
    "        code_groups_for_all_comps[(layer, \"attn\", ccb_num)] = partition_input_on_codebook(\n",
    "            cb_model=cb_model, automata=automata, layer=layer, cb_at=\"attn\", ccb_num=ccb_num, input_len=repeat\n",
    "        )\n",
    "    code_groups_for_all_comps[(layer, \"mlp\", None)] = partition_input_on_codebook(\n",
    "        cb_model=cb_model, automata=automata, layer=layer, cb_at=\"mlp\", ccb_num=None, input_len=repeat\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in range(cb_model.cfg.n_layers):\n",
    "    for cb_at in [\"attn\", \"mlp\"]:\n",
    "        for ccb_num in range(cb_model.cfg.n_heads) if cb_at == \"attn\" else [None]:\n",
    "            plot_js_div(code_groups_for_all_comps, layer, cb_at, ccb_num, js_divs, show_plot=False, image_name_prefix=\"k4_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10,  0,  0]], device='cuda:0')\n",
      "[('6', 0.2214595377445221), ('9', 0.18503721058368683), ('0', 0.17624445259571075), ('4', 0.14047598838806152), ('8', 0.11677603423595428)]\n",
      "[('6', 0.1748712658882141), ('4', 0.1526215821504593), ('0', 0.14920181035995483), ('9', 0.1374754011631012), ('8', 0.12292425334453583)]\n"
     ]
    }
   ],
   "source": [
    "cb_model.reset_hook_kwargs()\n",
    "# cb_model.all_codebooks[1][1].set_hook_kwargs(disable_codes=[6486], keep_k_codes=False, disable_for_tkns=[-1])\n",
    "# cb_model.all_codebooks[2][1].set_hook_kwargs(disable_codes=[8406], keep_k_codes=False, disable_for_tkns=[-1])\n",
    "# cb_model.set_hook_kwargs(idx=[1], disable_topk=1, keep_k_codes=False, disable_for_tkns=[-1])\n",
    "# cb_model.all_codebooks[3][1].set_hook_kwargs(disable_codes=[111], keep_k_codes=False, disable_for_tkns=[-1])\n",
    "base_str = \"00\"\n",
    "base_input = cb_model.to_tokens(base_str, prepend_bos=True)\n",
    "print(base_input)\n",
    "base_input = base_input.to(device)\n",
    "base_logits, base_cache = cb_model.run_with_cache(base_input)\n",
    "print(logits_to_pred(base_logits))\n",
    "\n",
    "cb_model.all_codebooks[3][1].set_hook_kwargs(disable_codes=[1185,16,111,902], keep_k_codes=False, disable_for_tkns=[-1])\n",
    "base_logits, base_cache = cb_model.run_with_cache(base_input)\n",
    "print(logits_to_pred(base_logits))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10240 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10240/10240 [00:01<00:00, 7586.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# 1,1 1,2\n",
    "layer = 3\n",
    "# ccb_num = 3\n",
    "# cb_at = \"attn\"\n",
    "cb_at = \"mlp\"\n",
    "if cb_at == \"attn\":\n",
    "    ccb = f\"_preproj_ccb{ccb_num}\"\n",
    "    indices = base_cache[f'blocks.{layer}.attn.codebook_layer.codebook.{ccb_num}.hook_codebook_ids'][0,-1].tolist()\n",
    "else:\n",
    "    ccb = \"\"\n",
    "    indices = base_cache[f'blocks.{layer}.mlp.codebook_layer.hook_codebook_ids'][0,-1].tolist()\n",
    "\n",
    "cb_str = f\"layer{layer}_{cb_at}{ccb}\"\n",
    "\n",
    "if (not cb_str in ft_tkns) or True:\n",
    "    ft_tkns[cb_str] = features_to_tokens_fast(cb_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_ft_tkns(ft_tkns[cb_str],n=5,indices=indices,max_examples=50)\n",
    "print_ft_tkns(ft_tkns[cb_str],n=5,indices=[111],max_examples=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_state_activations(33, cb_at=\"attn\", layer=0, ccb_num=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in range(cb_model.cfg.n_layers):\n",
    "    for head in range(cb_model.cfg.n_heads):\n",
    "        print(layer, head, start_state_activations(63, cb_at=\"attn\", layer=layer, ccb_num=head))\n",
    "    # print(layer, start_state_activations(63, cb_at=\"mlp\", layer=layer, ccb_num=None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code [4776]\n",
      "[33]\n"
     ]
    }
   ],
   "source": [
    "print(start_state_activations(63, cb_at=\"mlp\", layer=1, ccb_num=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "# print(generate_with_codes(\"<|endoftext|>00\", [5], [\"attn\"], layer_idx=[2], head_idx=[3], pos=[-1]))\n",
    "disable_other_comps = True\n",
    "code = [8268]\n",
    "cb_at = [\"mlp\"]\n",
    "layer_idx = [3]\n",
    "head_idx = [1]\n",
    "pos = [-1]\n",
    "list_of_arg_tuples = [CodeInfoTuple(code[i], cb_at[i], layer_idx[i], head_idx[i], pos[i]) for i in range(len(code))]\n",
    "print(generate_with_codes(\"<|endoftext|>33\", list_of_arg_tuples=list_of_arg_tuples, disable_other_comps=disable_other_comps))\n",
    "# print(generate_with_codes(\"<|endoftext|>011\", list_of_arg_tuples=list_of_arg_tuples, disable_other_comps=disable_other_comps))\n",
    "# print(generate_with_codes(\"<|endoftext|>10\", list_of_arg_tuples=list_of_arg_tuples, disable_other_comps=disable_other_comps))\n",
    "# print(generate_with_codes(\"<|endoftext|>110\", list_of_arg_tuples=list_of_arg_tuples, disable_other_comps=disable_other_comps))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_model.generate(max_new_tokens=60, do_sample=True, stop_at_eos=True,prepend_bos=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
